{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tal144155/DTS_Project/blob/main/TDS_Project_p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o9quY7wOSoY"
   },
   "source": [
    "# Tabular Data Science - Research Project\n",
    "### Group Members: \n",
    "* Tal Ariel Ziv\n",
    "* Arnon Lutsky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwiIVc94PnnJ"
   },
   "source": [
    "#### Introduction\n",
    "Our final project aims to enhance and automate the data visualization process within the data science pipeline. Visualization is a critical step in understanding the data, allowing users to explore distributions, analyze relationships between features and target variables, and gain meaningful insights from different perspectives. By improving and automating this process, we seek to make data exploration more efficient, more intuitive, and accessible. Our solution is an algorithm that automatically analyzes the data for different statistical relations and interesting observations and recommends visualizations based on analysis and a recommendation system.<br>\n",
    "\n",
    "Before we begin, let's install all packages that are needed to run the notebook.\n",
    "#### Installation Guide:\n",
    "1. Download python **version 3.12** (and up). You can use the following [link](https://www.python.org/downloads/).\n",
    "2. Please download all required packages, using the following command (write it in your CMD): `pip install -r requirements.txt`<br><br>\n",
    "<font size=4px>**Now, we are able to begin.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation Detection Algorithm:\n",
    "\n",
    "For deeper understanging of the relation detection algorithm, please refer to the pdf with the full explanaion of the project, under Relation Detection Algorithm, section 2.1 .\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets start analyzing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lTDiV-NNiXy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os.path\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from plot_generator import *\n",
    "from recommendation_tool import *\n",
    "from relation_detection_algorithm import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understanding The Data\n",
    "Now, let's define the functions that will find the relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set the top 10 relations as the default number of relations returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_RELATIONS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the relation detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATION_TYPES = {\n",
    "    \"high_correlation\": {\n",
    "        \"description\": \"Identifies pairs of numerical features that have a strong linear relationship, indicating potential multicollinearity or redundancy in the dataset.\",\n",
    "        \"use_cases\": [\n",
    "            \"Feature selection\",\n",
    "            \"Dimensionality reduction\",\n",
    "            \"Understanding feature interactions\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'target_correlation': {\n",
    "        \"description\": \"Measures the linear relationship between individual features and the target variable, helping to identify the most influential predictors.\",\n",
    "        \"use_cases\": [\n",
    "            \"Feature importance ranking\",\n",
    "            \"Predictive modeling\",\n",
    "            \"Feature selection\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'categorical_effect': {\n",
    "        \"description\": \"Evaluates the statistical significance of categorical variables' impact on a numerical target variable using one-way ANOVA test.\",\n",
    "        \"use_cases\": [\n",
    "            \"Feature significance testing\",\n",
    "            \"Group comparison\",\n",
    "            \"Categorical feature importance\"\n",
    "        ],\n",
    "        \"data_types\": [\"categorical\", \"numerical\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'chi_squared': {\n",
    "        \"description\": \"Identifies statistically significant relationships between categorical variables using the chi-squared independence test.\",\n",
    "        \"use_cases\": [\n",
    "            \"Feature dependency analysis\",\n",
    "            \"Categorical variable interaction detection\",\n",
    "            \"Feature selection\"\n",
    "        ],\n",
    "        \"data_types\": [\"categorical\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'date_numerical_trend': {\n",
    "        \"description\": \"Detects temporal trends in numerical features by measuring their correlation with time-based attributes.\",\n",
    "        \"use_cases\": [\n",
    "            \"Time series analysis\",\n",
    "            \"Trend identification\",\n",
    "            \"Temporal pattern recognition\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\", \"time series\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'date_categorical_distribution': {\n",
    "        \"description\": \"Analyzes how categorical variable distributions change or are distributed across different time periods.\",\n",
    "        \"use_cases\": [\n",
    "            \"Temporal categorical pattern detection\",\n",
    "            \"Seasonal variation analysis\",\n",
    "            \"Time-based segmentation\"\n",
    "        ],\n",
    "        \"data_types\": [\"categorical\", \"time series\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'non_linear': {\n",
    "        \"description\": \"Identifies complex, non-linear relationships between numerical features using mutual information score.\",\n",
    "        \"use_cases\": [\n",
    "            \"Advanced feature interaction detection\",\n",
    "            \"Non-linear dependency analysis\",\n",
    "            \"Complex relationship mapping\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'feature_importance': {\n",
    "        \"description\": \"Ranks features based on their predictive power using a Random Forest Regressor's feature importance metric.\",\n",
    "        \"use_cases\": [\n",
    "            \"Predictive modeling\",\n",
    "            \"Feature selection\",\n",
    "            \"Model interpretability\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'outlier_pattern': {\n",
    "        \"description\": \"Detects unique correlation patterns among outliers that differ from the overall dataset's correlations.\",\n",
    "        \"use_cases\": [\n",
    "            \"Anomaly detection\",\n",
    "            \"Robust correlation analysis\",\n",
    "            \"Outlier impact assessment\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\"],\n",
    "        \"dimensions\": [2],\n",
    "    },\n",
    "    'cluster_group': {\n",
    "        \"description\": \"Identifies groups of features that exhibit similar clustering characteristics based on their importance within specific clusters.\",\n",
    "        \"use_cases\": [\n",
    "            \"Feature grouping\",\n",
    "            \"Dimensionality reduction\",\n",
    "            \"Structural data understanding\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\"],\n",
    "        \"dimensions\": [1],\n",
    "    },\n",
    "    'target_analysis': {\n",
    "        \"description\": \"Provides a comprehensive analysis of the target variable, including outlier characteristics and distribution properties.\",\n",
    "        \"use_cases\": [\n",
    "            \"Target variable understanding\",\n",
    "            \"Distribution fitting\",\n",
    "            \"Outlier detection\"\n",
    "        ],\n",
    "        \"data_types\": [\"numerical\"],\n",
    "        \"dimensions\": [1],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load a dataset, this will be the movie dataset on which we worked on the last parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'date': pd.date_range(start='2023-01-01', periods=12, freq='M'),\n",
    "    'category': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'value': [8, 15, 7, 12, 18, 9, 14, 20, 11, 16, 22, 13],\n",
    "    'count': [100, 150, 70, 120, 180, 90, 140, 200, 110, 160, 220, 130]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll load the existing user ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = load_ratings('user_ratings_rel2', RELATION_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = input(\"Please enter a user id:\\n\")\n",
    "\n",
    "# If this is a new user, add the user to the dataframe.\n",
    "if not user_id in ratings.index:\n",
    "    ratings.loc[user_id] = np.nan\n",
    "    save_ratings(ratings, 'user_ratings_rel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_value = 'value'\n",
    "# Load user ratings from the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get automatic recommendations \n",
    "dataset_types = get_column_types(data)\n",
    "algo_rec = find_relations(data, target_value, dataset_types)\n",
    "algo_rec = get_relation_scores(algo_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    if not algo_rec:\n",
    "        print(\"Those are all the meaningful relations we've found.\\n We hope you found this helpful! (:)\")\n",
    "        break\n",
    "    # Get the current user ratings\n",
    "    # ratings = load_ratings('user_ratings_rel', RELATION_TYPES)\n",
    "    combined_user_vis_pred = combine_pred(CFIB(ratings), CFUB(ratings), 0.5, 0.5)\n",
    "\n",
    "    # Make a df for the recommendation system\n",
    "    algo_rec_df = get_top_relations(algo_rec)\n",
    "\n",
    "\n",
    "    user_index = ratings.index.get_loc(user_id)\n",
    "    recommendations = combine_pred(combined_user_vis_pred[user_index], algo_rec_df.to_numpy()[0], 0.7, 0.3)\n",
    "    \n",
    "    # Print the top recommendations sorted by score\n",
    "    print(\"Recommended visualizations:\")\n",
    "    index = int(algo_rec_df.iloc[1,recommendations.argmax()])\n",
    "    rec = algo_rec.pop(index)\n",
    "    user_rating = 0\n",
    "    if pd.notna(ratings.loc[user_id, rec['relation_type']]):\n",
    "        user_rating = ratings.loc[user_id, rec['relation_type']]\n",
    "\n",
    "    print(f\"\\n    {rec['relation_type'].replace('_', ' ').title()}\")\n",
    "    print(f\"   Description: {RELATION_TYPES[rec['relation_type']]['description']}\")\n",
    "    print(f\"   Score: {recommendations[index]}\")\n",
    "    print(f\"   Rationale:\")\n",
    "    for exp in rec['details']:\n",
    "        print(f\"   - {exp}\")\n",
    "    \n",
    "    new_rating = int(input(RATING_STRING))\n",
    "    if user_rating:\n",
    "        ratings.loc[user_id, rec['relation_type']] = user_rating * 0.8 + new_rating* 0.2\n",
    "    else:\n",
    "        ratings.loc[user_id, rec['relation_type']] = new_rating\n",
    "\n",
    "    save_ratings(ratings, 'user_ratings_rel')    \n",
    "\n",
    "\n",
    "\n",
    "    print(f'\\n {ratings} \\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
